# 分布式锁方案

## 背景

在讨论这个问题之前，我们先来看一个业务场景：
系统A是一个电商系统，目前是单机部署，系统中提供了一个用户下订单的接口（用户下订单之前一定会检查库存，确保库存足够了，才会给用户下单）。为了保证并发，我们预先将商品的库存保存在Redis中，用户下单的时候更新Redis的库存。此时系统架构如下：
![order](https://leetan.oss-cn-beijing.aliyuncs.com/code/order.png)
**该流程存在隐患**：即在某个时刻，Redis中某个商品的库存为10，此时两个请求同时到来，其中一个请求执行到上图的第三步，更新数据库的库存为9，但是第四步还没有执行。而另外一个请求执行到了第二步，发现库存还是10，就继续执行第3步。这样就会导致时间卖出了2个商品，但库存剩余未9（库存的场景出现这种情况还好，可以通过其他方式补偿。但是当银行的用户之间转账出现这种情况就不能接受了)。

在单体系统中我们很容易想到用synchronized关键字或ReentrantLock（前提是开发语言Java）来对共享资源锁定。如下图所示：
![order-lock](https://leetan.oss-cn-beijing.aliyuncs.com/code/order-lock.png)

即在执行第二步前对共享资源加锁，当订单创建完成后释放锁资源，保证多个线程之间只能串行化执行，即可避免并发导致的上述问题。不过，当用户量增加，系统压力变大时，我们会选择多实例部署，此时系统架构如下图所示

![order-lock-java](https://leetan.oss-cn-beijing.aliyuncs.com/code/order-lock-java.png)

如果，此时两个用户的请求同时到来，但是分发到了不同的实例上，那么这两个请求是可以同时执行了，还是会出现上述库存超卖的问题。Java提供的原生锁机制在多机部署场景下就无能为力了。

。。。。。。。
。。。。。。。。。。
。。。。。。。。。。。。
。。。。。。。。。。
。。。。。。。

此时，分布式锁就该隆重登场了。分布式锁的思路是：在整个系统提供一个**全局、唯一的「东西」**，然后每个系统在需要加锁时，都到这个「东西」获得一把锁，这样不同的系统得到的就是同一把锁。所以上图同加锁方式就从获取Java原生锁变成了从某个地方获取全局锁的架构。如下图所示：

![order-lock](https://leetan.oss-cn-beijing.aliyuncs.com/code/order-lock-redis.png)

分布式锁应该满足以下条件：


1. 分布式系统环境下，一个代码块在同一时间只能被一个机器的一个线程执行
2. 高可用的获取锁和释放锁
3. 具备可重入特性
4. 具备锁失效机制，防止死锁
5. 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败

## 常用解决方案

>为了解决并发问题的分布式锁可以通过数据库、Redis、Zookeeper等来实现。

### 1、基于Mysql实现分布式锁 （乐观锁）

>Mysql实现分布式锁 主要是基于数据库的排他锁(也叫行级排他锁)， 采用乐观锁的方式去做。

```
`先看加锁Sql语句：
update t_cluster_lock 
    set version = ?, 
        execute_ip = ?, 
        update_time = ? 
    where thread_name = ? 
        and version = ?`
```

业务逻辑实现：就是每次在需要加锁的时候直接执行上面的sql语句即可，当执行成功时，即表示加锁成功，可以继续下面的业务逻辑；当执行失败时，说明有其他任务正在占有该资源，需要等待、重试，直到成功获取到锁资源或超时为止。该方案实现简单、容易理解。但是在高并发的情况下，基于类似于Mysql这种关系型数据库的分布式锁的实现会变成系统的性能瓶颈。

### 2、基于Redis的分布式锁实现

>使用Redis做分布式锁的思路大体是：在Redis中设置一个值表示加了锁，然后释放锁的时候就把这个key删除。


最简单的是，直接利用Redis的NX操作（只有指定的key不存在时，才能成功设置）。伪代码：

```
`/**`
` * 1、获取锁`
` */`` `
`SET anyLock unique_value NX PX ``30000`` ``// NX是指如果key不存在就成功，key存在返回false，PX可以指定过期时间`

/**
 * 2、执行业务逻辑
 *    减少库存、保存订单 ......
 */


/**
 * 3、释放锁：通过执行一段lua脚本
 *   释放锁涉及到两条指令，这两条指令不是原子性的(需要用到redis的lua脚本支持特性，redis执行lua脚本是原子性的)
 */
`if`` redis``.``call``(``"get"``,`` KEYS``[``1``])`` ``==`` ARGV``[``1``]`` ``then`
`return`` redis``.``call``(``"del"``,`` KEYS``[``1``])`
```

这种方案有几大要点：

* 用SET key value NX PX milliseconds 命令

        如果是先设置了值，再设置过期时间，那么，这个就不是原子性操作，有可能在设置过期时间前宕机，会造成死锁(key永久存在)

* value要具有唯一性

        这个是为了在解锁的时候，需要验证value是和加锁的一致才删除key。这是为了避免这种情况：假设A获取了锁，过期时间30s，此时35s之后，锁已经自动释放了，A去释放锁，但是此时可能B获取了锁。因为value值也预期的不一致，所以A客户端就不能删除B的锁了。

**需要注意的是**：如果采用单机部署Redis，当出现单点故障，那么分布式锁就无法获取了。所以一般会采用**[master-slave + sentinel选举模式](https://www.jianshu.com/p/2d39b0c3f30b)、[cluster模式](https://www.jianshu.com/p/49c9e03eef23)**来部署Redis，保证缓存系统的可用性。
采用master-slave模式，加锁的时候只对一个节点加锁，即便通过sentinel做了高可用，但是如果master节点故障了，发生主从切换，此时就会有可能出现锁丢失的问题。

基于上述问题Redis的作者提出了一个RedLock的算法。大概意思，假设redis的部署模式是redis-cluster，总共有5个master节点，通过以下步骤获取一把锁：

![](https://leetan.oss-cn-beijing.aliyuncs.com/code/redis-lock.png)

获取当前时间戳，单位是毫秒

2. 轮流尝试在每个Master节点上创建锁，过期时间设置较短，一般就几十毫秒
3. 尝试在大多数节点上建立一个锁，比如5个节点就要求是3个节点（n / 2 +1）
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了
5. 要是锁建立失败了，那么就依次删除这个锁
6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁

大家可以思考一下，这种方案会不会有其他问题的出现......

**推荐工具-Redisson**

除了基于Redis Client的原生api来实现分布式锁外，还可以直接使用企业级Java开源框架：[Redisson](https://redisson.org/)。

回想一下上面讲的基于Redis api实现分布式锁伪代码第一步，如果写代码来通过Redis设置一个值，是通过下面这个命令设置的。

```
SET anyLock unique_value NX PX 30000
```

这里设置的超时时间是30s，假如超过30s都还没有完成业务逻辑的情况下，key会过期，其他线程有可能会获取到锁。这样一来的话，第一个线程还没执行完业务逻辑，第二个线程进来了也会出现线程安全问题（请思考一下这个问题应该怎么解决）。

Redisson是怎么解决这个问题的呢？先来看一下相关代码

```
`Config config = new Config();
``config.useClusterServers()
    ``.addNodeAddress("redis://192.168.31.101:7001")
    ``.addNodeAddress("redis://192.168.31.101:7002")
    ``.addNodeAddress("redis://192.168.31.101:7003")
    ``.addNodeAddress("redis://192.168.31.102:7001")
    ``.addNodeAddress("redis://192.168.31.102:7002")
    ``.addNodeAddress("redis://192.168.31.102:7003");
`` RedissonClient redisson = Redisson.create(config);
 ``RLock lock = redisson.getLock("anyLock");
 l``ock.lock();
 // 业务逻辑
 ``lock.unlock();

`
```

我们只需要通过它的api中的lock和unlock即可完成分布式锁。它帮我们考虑了很多细节：

* redisson所有指令都通过lua脚本执行，redis支持lua脚本原子性执行
* redisson设置一个key的默认过期时间为30s,如果某个客户端持有一个锁超过了30s怎么办？
* redisson中有一个`watchdog`的概念，翻译过来就是看门狗，它会在你获取锁之后，每隔10秒帮你把key的超时时间设为30s这样的话，就算一直持有锁也不会出现key过期了，其他线程获取到锁的问题了。redisson的“看门狗”逻辑保证了没有死锁发生。(如果机器宕机了，看门狗也就没了。此时就不会延长key的过期时间，到了30s之后就会自动过期了，其他线程可以获取到锁)


以上便是使用Redis来实现分布式锁的方案以及其一些局限性。

### 3、基于Zookeeper的分布式锁实现

常见的分布式锁实现方案里面，除了使用Redis来实现之外，使用Zookeeper(下文用zk代替)也可以实现分布式锁。

介绍zk实现分布式锁的机制之前，我们先简单了解一下zk是什么：

概念：zk是一种提供配置管理、分布式协同以及命名的中心化服务。
zk的模型：zk包含一系列的节点（znode），就像文件系统一样，每个znode表示一个目录。znode有一些特性：

* 有序节点：假如当前有一个父节点为`/lock`，我们可以在这个父节点下面创建子节点。zk提供了一个可选的有序特性，例如我们可以创建子节点“/lock/node-”并且指明有序，那么zk在生成子节点时会根据当前的子节点数量自动添加整数序号。即，如果是第一个创建的子节点为`/lock/node-0000000000`，下一个节点则为`/lock/node-0000000001`，依次类推
* 临时节点：客户端可以建立一个临时节点，在会话结束或者会话超时后，zookeeper会自动删除该节点
* 事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zk会通知客户端。当前zk有如下四种事件：
    * 节点创建
    * 节点删除
    * 节点数据修改
    * 子节点变更


基于zk以上的一些特性，我们很容易得出使用zk实现分布式锁的落地方案：

1. 使用zk的临时节点和有序节点。每个线程获取锁时就在zk创建一个临时有序的节点，比如在/lock/目录下
2. 创建节点成功后，获取/lock目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点中序号最小的节点
3. 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功
4. 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的前一个节点添加一个事件监听（比如当前线程获取到的节点序号为`/lock/003`,然后所有的节点列表为`[/lock/001,/lock/002,/lock/003]`,则对`/lock/002`这个节点添加一个事件监听器）
5. 如果锁释放了，会唤醒下一个序号的节点，然后重新执行第3步，判断是否自己的节点序号是最小（比如`/lock/001`释放了，`/lock/002`监听到事件，此时节点集合为`[/lock/002,/lock/003]`,则`/lock/002`为最小序号节点，获取到锁）

![](https://leetan.oss-cn-beijing.aliyuncs.com/code/lock-num.png)
说实话，上面的逻辑看着简单，但是实现起来还是有点复杂......

推荐工具-Curator

Curator是一个zookeeper的开源客户端，也提供了分布式锁的实现。

```
InterProcessMutex interProcessMutex = new InterProcessMutex(client,"/anyLock");

// 获取锁

// 获取锁
interProcessMutex.acquire();
interProcessMutex.acquire();

/// 执行业务逻辑

// 释放锁
逻辑

// 释放锁
interProcessMutex.release();interProcessMutex.release();
```



## Redis和ZK方案对比


对于redis分布式锁而言，它有以下缺点：

* 它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能
* redis 创建锁的客户端如果挂了，只能等待超时后解锁
* 另外，Redis的设计定位决定了它的数据并不是强一致性的，在某些极端情况下，可能会出现问题
* 锁的模型不够健壮，即便使用Redlock算法来实现，在某些复杂场景下，也无法保证其实现100%没有问题


但是使用Redis实现分布式锁在很多企业中非常常见，而且大部分情况下都不会遇到所谓的“极端复杂场景”，所以使用Redis作为分布式锁也不失为一种好的方案，最重要的一点是redis的性能很高，可以支撑高并发的获取、释放锁操作。


对于zk分布式锁而言:

* zk天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁
* 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小
* zk在客户端挂了后就会自动释放锁

但是相比Redis，zk也有其缺点：性能上可能并没有Redis服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。